# Importing the libraries needed for this script.
library(shiny)
library(ggplot2)

# Creating the user interface (UI).
ui <- fluidPage(
  
  # Making the title
  h1("Gene Analysis", style = "color: white; background-color: navy; padding: 10px; text-align: center;"),
  
  # Adding tabs so the user can navigate between the pipeline analysis and alternative pipeline analysis.
  navbarPage(
    
    # Apply custom CSS for the top bar so that it is a different color from the rest of the page.
    tags$head(
      tags$style(HTML("
        .navbar-default {
          background-color: navy;
          border-color: navy;
        }
      "))
    ),
    
    # Tab for the pipeline analysis
    tabPanel("Pipeline Analysis", 
             # Summary of analyses (mandatory)
             mainPanel(
               h3("Conducting a pipeline analysis "),
               uiOutput("summary1"),
             ),
             
             # Making the gene query interface for tab1 (Pipeline analysis)
             sidebarPanel(
               h3("Gene Query"),
               textInput("gene_query1", label = "Enter Gene ID"),  
               verbatimTextOutput("gene_info1"),
               selectInput("plot_type1", label = "Additional graphs",
                           choices = c("Scatter Plot", "Bar Plot")),
               plotOutput("plot1")  
             )
    ),
    
    # Tab for the alternative pipeline analysis 
    tabPanel("Alternative Pipeline Analysis", 
             # Add UI elements for the second page
             mainPanel(
               h3("Conducting an alternative pipeline analysis using Seurat "),
               uiOutput("summary2"),
               
               # Adding images of the visualization of the analysis
               h3("Visualization of results"),
               fluidRow(
                 column(width = 6, imageOutput("data_image1")),
                 column(width = 6, imageOutput("data_image2")),
                 column(width = 6, imageOutput("data_image3")),
                 column(width = 6, imageOutput("data_image4"))
               ),
               fluidRow(
                 column(width = 6, imageOutput("data_image5")),
                 column(width = 6, imageOutput("data_image6")),
                 column(width = 6, imageOutput("data_image7")),
                 column(width = 6, imageOutput("data_image8"))
               )
             ),
             
             # Adding links to the interactive plots HTML files
             sidebarPanel(
               h3("Interactive Plots"),
               tags$div(tags$a(href = "interactive_tsne_plot.html", target = "_blank", "View Interactive tSNE Plot")),
               tags$div(tags$a(href = "interactive_umap_plot.html", target = "_blank", "View Interactive Umap Plot"))
             ),
             
             # Making the gene query interface for tab2 (Alternative pipeline analysis)
             sidebarPanel(
               h3("Gene Query"),
               textInput("gene_query2", label = "Enter Gene ID (Eg s0867_mouse6_HBRX2353_Tumor_1cells)"),  # Change the label to "Enter Gene ID"
               verbatimTextOutput("gene_info2"),
               selectInput("plot_type2", label = "Additional graphs",
                           choices = c("Scatter Plot", "Bar Plot")),
               plotOutput("plot2")  
             )
    )
  )
)

# Server
server <- function(input, output) {
  
  # Load data for Pipeline Analysis tab
  data_pipeline <- read.csv("gene_data.csv")
  
  # Summary of analyses for Pipeline Analysis tab
  output$summary1 <- renderUI({  
    text <- " Re-analyzing the RNA sequencing data, as outlined by Hamelin et al., involved a meticulous series of steps aimed at processing, analyzing, and interpreting the dataset. Initially, data retrieval and preparation were prioritized, with RNA sequencing data obtained from the GEO and SRA databases. This involved writing Bash scripts to download and convert files to the necessary fastq format, ensuring compatibility for subsequent analysis. Additionally, the configuration of the SRA toolkit and monitoring of download progress were essential tasks during this phase.
Following data retrieval, read alignment using STAR was conducted to map sequencing reads to the human genome. This process necessitated the creation of directories for organization and structure, as well as indexing of the reference genome and gene annotation files. To expedite the mapping process and manage computational resources effectively, workload splitting was implemented through the submission of multiple job scripts.
Once alignment was completed, sorting and indexing of BAM files were performed using Samtools. Monitoring job progress and ensuring error-free execution were critical aspects of this phase. Subsequently, coverage tracks were generated using R, facilitating visualization and further analysis of read coverage across the genome. Feature counting using Rsubread complemented this step, providing insights into the number of reads overlapping with gene exons.
Addressing potential artifacts such as doublets and multiplets was crucial for data quality assurance. Microscopy observation and fastq_screen assessment were employed to identify and eliminate wells with multiple cells or debris. Libraries failing to meet predefined criteria based on human-to-mouse ratios and read counts were excluded from further analysis.
Inference and correction of cell cycle signals were then performed to account for cell cycle-related variability in gene expression data. Utilizing known cell cycle-regulated genes, cell cycle stages were inferred and cells were assigned accordingly. Additionally, modeling and regression techniques were applied to remove cell cycle and library complexity effects from the gene expression data.
Dimensionality reduction, clustering, and differential expression analyses provided deeper insights into the dataset. Techniques such as PCA, tSNE, and UMAP were employed for dimensionality reduction, followed by Louvain clustering for identifying distinct cell populations. Pairwise t-tests and gene set enrichment analysis further elucidated differential gene expression patterns and enriched biological pathways.
Finally, data retrieval from external databases, such as KMplotter, enabled additional analyses such as Kaplan-Meier survival analysis. Further refinement involved isolating upregulated transcripts and conducting additional analyses, such as recurrence-free survival (RFS) analysis on specific patient cohorts. These comprehensive analytical steps collectively contributed to the thorough re-analysis of the RNA sequencing data in alignment with the methodology outlined by Hamelin et al.
"
    # Split text into paragraphs
    paragraphs <- strsplit(text, "\n")[[1]]  
    HTML(paste("<p>", paragraphs, "</p>", collapse = "<br>"))
  })
  
  # Load data for Alternative Pipeline Analysis tab
  data_alternative <- read.csv("metadata.csv")
  
  # Summary of analyses for Alternative Pipeline Analysis tab
  output$summary2 <- renderUI({  
    text <- "The re-analysis of the Hamelin et al. paper was conducted using an alternative pipeline for several reasons. This approach aimed to enhance the credibility and reliability of the research by verifying the findings of the paper and ensuring the results are not dependent on specific analytical approaches or methodologies. 
  An alternative pipeline can identify potential biases or errors present in the original analysis. By using different techniques or algorithms, researchers can identify and improve potential sources of bias or inaccuracies in the data or analysis methods. In addition, it allows researchers to explore alternative explanations or interpretations of the data. This can lead to new insights or perspectives based on the study. As scientific methods and analytical techniques evolve over time. Re-analysis with newer, efficient or more advanced pipelines may leverage improvements in methodology which were not available in the original study. Moreover, it provides a chance for cross-validation of the results, enhancing confidence in the study's validity.
  The alternative pipeline analysis was executed using Seurat, following the methodology outlined by Wang Rui et al. This selection was made due to the comprehensive assessment of cancer via scRNAseq analysis presented in their study. This aligned closely with the methodology employed using scRNAseq in the original research conducted by Hamelin et al. Seurat is a powerful tool for scRNA-seq analysis, offering numerous advantages in terms of functionality and reliability.
  The pipeline analysis started with downloading the relevant data from the GEO using the accession code and the raw data was downloaded. This process was similar to the original study. Following this, the relevant R packages, including Seurat and ggplot, were installed and incorporated onto the R session. Subsequently, the CSV dataset was imported for further analysis. Various analytical procedures were then executed, including preprocessing, normalization, variable feature selection, scaling, PCA, clustering and UMAP visualisation."
    # Split text into paragraphs    
    paragraphs <- strsplit(text, "\n")[[1]]  
    HTML(paste("<p>", paragraphs, "</p>", collapse = "<br>"))
  })
  
  # File paths for all the images displayed on the tabs
  output$data_image1 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image1.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image2 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image2.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image3 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image3.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image4 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image4.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image5 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image5.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image6 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image6.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image7 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image7.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  output$data_image8 <- renderImage({
    list(src = "/home/ssgk1/my_apps/www/image8.png",
         width = "100%",
         height = 400)
  }, deleteFile = F)
  
  # Gene query functionality for tab1 (Pipeline Analysis)
  output$gene_info1 <- renderPrint({
    gene_id <- input$gene_query1  # Retrieve gene ID from input
    if (!is.null(gene_id)) {
      gene_info <- data_pipeline[data_pipeline$Gene == gene_id, ]  # Filter data based on Gene column
      if (nrow(gene_info) > 0) {
        gene_info
      } else {
        "Gene ID not found"
      }
    }
  })
  
  # Gene query functionality for tab2 (Alternative Pipeline Analysis)  
  output$gene_info2 <- renderPrint({
    gene_id <- input$gene_query2  # Retrieve gene ID from input
    if (!is.null(gene_id)) {
      gene_info <- data_alternative[data_alternative$ID == gene_id, ]  # Filter data based on ID
      if (nrow(gene_info) > 0) {
        gene_info
      } else {
        "Gene ID not found"
      }
    }
  })
  
  # Render different types of plots based on user input for tab1 (Pipeline analysis)
  output$plot1 <- renderPlot({
    # Check the selected plot type
    if (input$plot_type1 == "Scatter Plot") {
      # Scatter plot
      ggplot(data_pipeline, aes_string(x = "X", y = "Y", color = "Cell_Type")) +
        geom_point() +
        labs(title = "Scatter Plot of Expression by Gene and Cell Type")
    } else if (input$plot_type1 == "Bar Plot") {
      # Bar plot
      ggplot(data_pipeline, aes_string(x = "Gene", y = "Expression", fill = "Cell_Type")) +
        geom_bar(stat = "identity") +
        labs(title = "Bar Plot of Expression by Gene and Cell Type")
    }
  })
  # Render different types of plots based on user input for tab2 (Alternative pipeline analysis)  
  output$plot2 <- renderPlot({
    # Check the selected plot type
    if (input$plot_type2 == "Scatter Plot") {
      # Scatter plot
      ggplot(data_alternative, aes(x = nCount_RNA, y = nFeature_RNA, color = clusters)) +
        geom_point() +
        labs(title = "Scatter Plot of Feature Count by Cell Type")
    } else if (input$plot_type2 == "Bar Plot") {
      # Bar plot
      ggplot(data_alternative, aes(x = Origin, y = clusters, fill = nCount_RNA)) +
        geom_bar(stat = "identity") +
        labs(title = "Bar Plot of RNA Count by Origin and Cell Type")
    }
  })
  
}
# Run the Shiny app
shinyApp(ui = ui, server = server)










# Importing the libraries needed for this script.
library(shiny)
library(data.table)

# Creating the user interface (UI).
ui <- fluidPage(
  # Making the title
  h1("Gene Analysis", style = "color: white; background-color: navy; padding: 10px; text-align: center;"),
  
  # Adding tabs so the user can navigate between the pipeline analysis and alternative pipeline analysis.
  navbarPage(
    # Apply custom CSS for the top bar so that it is a different color from the rest of the page.
    tags$head(
      tags$style(HTML("
        .navbar-default {
          background-color: navy;
          border-color: navy;
        }
      "))
    ),
    
    # Tab for the pipeline analysis
    tabPanel("Pipeline (Re-Analysis)", 
             # Summary of analyses (mandatory)
             sidebarLayout(
               sidebarPanel(
                 h3("Conducting the pipeline (re-analysis) "),
                 uiOutput("summary1"),
                 
                 # Making the gene query interface for tab1 (Pipeline Analysis)
                 h3("Gene Query"),
                 textInput("gene_query1", label = "Enter Gene ID (Eg s0867_mouse6_HBRX2353_Tumor_1cells)"),  # Change the label to "Enter Gene ID"
                 verbatimTextOutput("gene_info1")
               ),
               mainPanel(
                 # Add interactive plots and gene query to top right
                 h3("Interactive Plots"),
                 lapply(c(
                   "interactiveDEGvolcanoplot.html",
                   "interactivedotplot.html",
                   "interactiveheatmap.html",
                   "interactivetsne.html",
                   "interactiveumap.html",
                   "nFeaturevsnCount.html",
                   "percent.mtagainstnCount.html",
                   "volcanoplot.html"
                 ), function(file) {
                   tags$div(tags$a(href = file, target = "_blank", file))
                 }),
                 # Images below the text with heading "Results"
                 h3("Results"),
                 fluidRow(
                   column(width = 4, imageOutput("data_image14")),
                   column(width = 4, imageOutput("data_image15")),
                   column(width = 4, imageOutput("data_image16")),
                   column(width = 4, imageOutput("data_image17")),
                   column(width = 4, imageOutput("data_image18"))
                 )
               )
             )
    ),
    
    # Tab for the alternative pipeline analysis 
    tabPanel("Alternative Pipeline (Novel Analysis)", 
             # Add UI elements for the second page
             sidebarLayout(
               sidebarPanel(
                 h3("Conducting the alternative pipeline (novel analysis)"),
                 uiOutput("summary2"),
                 
                 # Making the gene query interface for tab2 (Alternative Pipeline Analysis)
                 h3("Gene Query"),
                 textInput("gene_query2", label = "Enter Gene ID (Eg s0867_mouse6_HBRX2353_Tumor_1cells)"),  # Change the label to "Enter Gene ID"
                 verbatimTextOutput("gene_info2")
               ),
               mainPanel(
                 # Adding images of the visualization of the analysis
                 h3("Results"),
                 fluidRow(
                   column(width = 6, imageOutput("data_image1")),
                   column(width = 6, imageOutput("data_image2")),
                   column(width = 6, imageOutput("data_image3")),
                   column(width = 6, imageOutput("data_image4")),
                   column(width = 6, imageOutput("data_image5")),
                   column(width = 6, imageOutput("data_image6")),
                   column(width = 6, imageOutput("data_image7")),
                   column(width = 6, imageOutput("data_image8")),
                   column(width = 6, imageOutput("data_image9")),
                   column(width = 6, imageOutput("data_image10")),
                   column(width = 6, imageOutput("data_image11")),
                   column(width = 6, imageOutput("data_image12")),
                   column(width = 6, imageOutput("data_image13"))
                 )
               )
             )
    )
  )
)

# Server
server <- function(input, output) {
  
  # Load large data for Pipeline Analysis tab
  data_normal <- reactive({
    req(input$gene_query1)
    fread("Logcount.csv")
  })
  
  # Load large data for Alternative Pipeline Analysis tab
  data_alternative <- reactive({
    req(input$gene_query2)
    fread("metadata.csv")
  })
  
  # Summary of analyses for Pipeline Analysis tab
  output$summary1 <- renderUI({  
    text <- " Re-analyzing the RNA sequencing data, as outlined by Hamelin et al., involved a meticulous series of steps aimed at processing, analyzing, and interpreting the dataset. Initially, data retrieval and preparation were prioritized, with RNA sequencing data obtained from the GEO and SRA databases. This involved writing Bash scripts to download and convert files to the necessary fastq format, ensuring compatibility for subsequent analysis. Additionally, the configuration of the SRA toolkit and monitoring of download progress were essential tasks during this phase.
Following data retrieval, read alignment using STAR was conducted to map sequencing reads to the human genome. This process necessitated the creation of directories for organization and structure, as well as indexing of the reference genome and gene annotation files. To expedite the mapping process and manage computational resources effectively, workload splitting was implemented through the submission of multiple job scripts.
Once alignment was completed, sorting and indexing of BAM files were performed using Samtools. Monitoring job progress and ensuring error-free execution were critical aspects of this phase. Subsequently, coverage tracks were generated using R, facilitating visualization and further analysis of read coverage across the genome. Feature counting using Rsubread complemented this step, providing insights into the number of reads overlapping with gene exons.
Addressing potential artifacts such as doublets and multiplets was crucial for data quality assurance. Microscopy observation and fastq_screen assessment were employed to identify and eliminate wells with multiple cells or debris. Libraries failing to meet predefined criteria based on human-to-mouse ratios and read counts were excluded from further analysis.
Inference and correction of cell cycle signals were then performed to account for cell cycle-related variability in gene expression data. Utilizing known cell cycle-regulated genes, cell cycle stages were inferred and cells were assigned accordingly. Additionally, modeling and regression techniques were applied to remove cell cycle and library complexity effects from the gene expression data.
Dimensionality reduction, clustering, and differential expression analyses provided deeper insights into the dataset. Techniques such as PCA, tSNE, and UMAP were employed for dimensionality reduction, followed by Louvain clustering for identifying distinct cell populations. Pairwise t-tests and gene set enrichment analysis further elucidated differential gene expression patterns and enriched biological pathways.
Finally, data retrieval from external databases, such as KMplotter, enabled additional analyses such as Kaplan-Meier survival analysis. Further refinement involved isolating upregulated transcripts and conducting additional analyses, such as recurrence-free survival (RFS) analysis on specific patient cohorts. These comprehensive analytical steps collectively contributed to the thorough re-analysis of the RNA sequencing data in alignment with the methodology outlined by Hamelin et al."
    # Split text into paragraphs
    paragraphs <- strsplit(text, "\n")[[1]]  
    HTML(paste("<p>", paragraphs, "</p>", collapse = "<br>"))
  })
  
  # Summary of analyses for Alternative Pipeline Analysis tab
  output$summary2 <- renderUI({  
    text <- "The re-analysis of the Hamelin et al. paper was conducted using an alternative pipeline for several reasons. This approach aimed to enhance the credibility and reliability of the research by verifying the findings of the paper and ensuring the results are not dependent on specific analytical approaches or methodologies. 
  An alternative pipeline can identify potential biases or errors present in the original analysis. By using different techniques or algorithms, researchers can identify and improve potential sources of bias or inaccuracies in the data or analysis methods. In addition, it allows researchers to explore alternative explanations or interpretations of the data. This can lead to new insights or perspectives based on the study. As scientific methods and analytical techniques evolve over time. Re-analysis with newer, efficient or more advanced pipelines may leverage improvements in methodology which were not available in the original study. Moreover, it provides a chance for cross-validation of the results, enhancing confidence in the study's validity.
  The alternative pipeline analysis was executed using Seurat, following the methodology outlined by Wang Rui et al. This selection was made due to the comprehensive assessment of cancer via scRNAseq analysis presented in their study. This aligned closely with the methodology employed using scRNAseq in the original research conducted by Hamelin et al. Seurat is a powerful tool for scRNA-seq analysis, offering numerous advantages in terms of functionality and reliability.
  The pipeline analysis started with downloading the relevant data from the GEO using the accession code and the raw data was downloaded. This process was similar to the original study. Following this, the relevant R packages, including Seurat and ggplot, were installed and incorporated onto the R session. Subsequently, the CSV dataset was imported for further analysis. Various analytical procedures were then executed, including preprocessing, normalization, variable feature selection, scaling, PCA, clustering and UMAP visualisation."
    # Split text into paragraphs    
    paragraphs <- strsplit(text, "\n")[[1]]  
    HTML(paste("<p>", paragraphs, "</p>", collapse = "<br>"))
  })
  
  # File paths for all the images displayed on the tabs
  output_data_images <- function(n) {
    renderImage({
      list(src = paste0("/home/ssgk1/my_apps/www/image", n, ".png"),
           width = 600,
           height = 400)
    }, deleteFile = F)
  }
  
  for (i in 1:18) {
    output[[paste0("data_image", i)]] <- output_data_images(i)
  }
  
  # Gene query functionality for tab1 (Pipeline Analysis)  
  output$gene_info1 <- renderPrint({
    gene_id <- input$gene_query1  # Retrieve gene ID from input
    if (!is.null(gene_id)) {
      gene_info <- data_normal()[data_normal()[,1] == gene_id, ]  # Filter data based on ID in the first column
      if (nrow(gene_info) > 0) {
        gene_info
      } else {
        "Gene ID not found"
      }
    }
  })
  
  # Gene query functionality for tab2 (Alternative Pipeline Analysis)  
  output$gene_info2 <- renderPrint({
    gene_id <- input$gene_query2  # Retrieve gene ID from input
    if (!is.null(gene_id)) {
      gene_info <- data_alternative()[data_alternative()[,1] == gene_id, ]  # Filter data based on ID in the first column
      if (nrow(gene_info) > 0) {
        gene_info
      } else {
        "Gene ID not found"
      }
    }
  })
}

# Run the application
shinyApp(ui = ui, server = server)
